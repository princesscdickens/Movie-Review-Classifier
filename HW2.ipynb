{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Princess Dickens, \n",
    "LING 6300, HW2\n",
    "\n",
    "# Cornell Movie Review\n",
    "\n",
    "1. There will be two classes: positive and negative. Build a count dictionary for each class.\n",
    "key = word\n",
    "value = count\n",
    "\n",
    "Ex) postive('great') = 669\n",
    "\n",
    "2. Figure out what the vocabulary is for both classes together - set() - and the size len(vocabulary). This way, you can initialize each dictionary with already-smoothed values, and keys from BOTH bags.\n",
    "    - Get set of words for both bags\n",
    "    - Initialize pos dict with all words and a count of 0.5\n",
    "    - Initialize neg dict with all words and a count of 0.5\n",
    "    - Go through training data and add real counts to each dict respectively\n",
    "    \n",
    "\n",
    "3. Design a function that takes a word and the dictionary and the vocabulary set (as a minimum) as arguments and the probability in that class.\n",
    "\n",
    "Ex) getp(mypositivecounts, vocabulary, 'great')\n",
    "\n",
    "4. Add smoothing to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posDict['great'] =  669\n",
      "negDict['great'] =  350\n",
      "Size of posDict:  35093\n",
      "Size of negDict:  32891\n",
      "Total tokens in posDict:  710749\n",
      "Total tokens in negDict:  635078\n",
      "Total types in vocabulary:  48622\n",
      "New size of posDict:  48622\n",
      "New size of negDict:  48622\n",
      "p('great'|pos) =  0.000882\n",
      "p('great'|neg) =  0.000513\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import math\n",
    "from decimal import *\n",
    "posDict = {}\n",
    "negDict = {}\n",
    "vocabulary = set()\n",
    "\n",
    "# Read lines from each file and split into list of words\n",
    "# Create dict {word:count}\n",
    "\n",
    "lines = [line.strip() for line in open('pos.train')]\n",
    "poswords = []\n",
    "for l in lines:\n",
    "     poswords.extend(l.split())\n",
    "\n",
    "for word in poswords:\n",
    "    if word not in posDict:\n",
    "        posDict[word] = 1\n",
    "    else:\n",
    "        posDict[word] += 1\n",
    "\n",
    "lines2 = [line.strip() for line in open(\"neg.train\")]\n",
    "negwords = []\n",
    "for l in lines2:\n",
    "    negwords.extend(l.split())\n",
    "\n",
    "for word in negwords:\n",
    "    if word not in negDict:\n",
    "        negDict[word] = 1\n",
    "    else:\n",
    "        negDict[word] += 1\n",
    "\n",
    "# test posDict['great']\n",
    "print(\"posDict['great'] = \", posDict['great'])\n",
    "# test negDict['great']\n",
    "print(\"negDict['great'] = \", negDict['great'])\n",
    "# size of posDict\n",
    "print(\"Size of posDict: \", len(posDict))\n",
    "# size of negDict\n",
    "print(\"Size of negDict: \", len(negDict))\n",
    "# total tokens in posDict\n",
    "pos_token_count = sum(posDict.values())\n",
    "print(\"Total tokens in posDict: \", pos_token_count)\n",
    "# total tokens in negDict\n",
    "neg_token_count = sum(negDict.values())\n",
    "print(\"Total tokens in negDict: \", neg_token_count)\n",
    "\n",
    "# merge two dicts to create one set \"vocabulary\"\n",
    "\n",
    "for key in posDict:\n",
    "    vocabulary.add(key)\n",
    "for key in negDict:\n",
    "    vocabulary.add(key)\n",
    "    \n",
    "print(\"Total types in vocabulary: \", len(vocabulary))\n",
    "\n",
    "# Add other words to posDict and negDict with count = 0\n",
    "\n",
    "for word in vocabulary:\n",
    "    if word not in posDict:\n",
    "        posDict[word] = 0\n",
    "    if word not in negDict:\n",
    "        negDict[word] = 0\n",
    "\n",
    "# new size of posDict\n",
    "print(\"New size of posDict: \", len(posDict))\n",
    "# new size of negDict\n",
    "print(\"New size of negDict: \", len(negDict))\n",
    "\n",
    "# get total count and pass in as argument in getP (pos and neg separately)\n",
    "#pos_token_count = sum(posDict.values())\n",
    "#neg_token_count = sum(negDict.values())\n",
    "\n",
    "def getP(inputDict, inputTokenCount, vocabulary, inputWord):\n",
    "    # Add smoothing \n",
    "    SMOOTHING_VAR = 1\n",
    "    count_with_smoothing = inputDict[inputWord] + SMOOTHING_VAR\n",
    "    new_total_tokens = inputTokenCount + (len(vocabulary) * SMOOTHING_VAR)\n",
    "    \n",
    "    # prob = (count for this word + smoothing val) / (total tokens + smoothing for every TYPE)\n",
    "    probability = count_with_smoothing / new_total_tokens       \n",
    "    \n",
    "    return round(probability, 6)\n",
    "\n",
    "print(\"p('great'|pos) = \", getP(posDict, pos_token_count, vocabulary, 'great'))\n",
    "print(\"p('great'|neg) = \", getP(negDict, neg_token_count, vocabulary, 'great'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words Naive Bayes Classifier\n",
    "Now that I've got a way of calculating the probability that a WORD is either positive or negative, I can add up the probabilities of a set number of words in a movie review to predict whether a movie review is positive or negative.\n",
    "\n",
    "Algorithm:\n",
    "1. Find the probability of each word, take the LOG of it, and add its score to the total. Do this with the positive and negative dictionaries separately. \n",
    "2. Compare the total scores for pos and neg. Whichever number is higher is the winner.\n",
    "3. Keep count of the winner to see how many positive and negative reviews it gets right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number positive for POS test set (correct):  82\n",
      "Number negative for POS test set (incorrect):  18\n"
     ]
    }
   ],
   "source": [
    "def classify_review(listWords, vocabulary):\n",
    "    #accepts list of words from review as argument instead of fileName\n",
    "    pos_prior = 0.5\n",
    "    posScore = math.log(pos_prior)\n",
    "    for word in listWords:\n",
    "        if word in vocabulary:\n",
    "            posScore += math.log(getP(posDict, pos_token_count, vocabulary, word))\n",
    "    \n",
    "    neg_prior = 0.5\n",
    "    negScore = math.log(neg_prior)\n",
    "    for word in listWords:\n",
    "        if word in vocabulary:\n",
    "            negScore += math.log(getP(negDict, neg_token_count, vocabulary, word))\n",
    "        \n",
    "    if posScore > negScore:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "# for POSITIVE test set\n",
    "\n",
    "pos_review_count = 0\n",
    "neg_review_count = 0\n",
    "\n",
    "# read multiple text files in a single directory\n",
    "\n",
    "file_dir1 = 'test/pos/'\n",
    "\n",
    "for fileName in os.listdir(file_dir1):\n",
    "    wordList = []\n",
    "    if 'txt' in fileName:\n",
    "        lines = [line.strip() for line in open(file_dir1 + fileName)]\n",
    "        for l in lines:\n",
    "            lineWords = l.split()\n",
    "            wordList.extend(lineWords)\n",
    "        \n",
    "        classification = classify_review(wordList, vocabulary)\n",
    "\n",
    "        if classification == 0:\n",
    "            #print(\"0\")\n",
    "            pos_review_count += 1\n",
    "            # This is a positive review\n",
    "        else:\n",
    "            #print(\"1\")\n",
    "            neg_review_count += 1\n",
    "            # This is a negative review\n",
    "            \n",
    "print(\"Number positive for POS test set (correct): \", pos_review_count)\n",
    "print(\"Number negative for POS test set (incorrect): \", neg_review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number positive for NEG test set (incorrect):  15\n",
      "Number negative for NEG test set (correct):  85\n"
     ]
    }
   ],
   "source": [
    "# For NEGATIVE test set\n",
    "\n",
    "pos_review_count2 = 0\n",
    "neg_review_count2 = 0\n",
    "\n",
    "file_dir2 = 'test/neg/'\n",
    "for fileName in os.listdir(file_dir2):\n",
    "    wordList = []\n",
    "    if 'txt' in fileName:\n",
    "        lines = [line.strip() for line in open(file_dir2 + fileName)]\n",
    "        for l in lines:\n",
    "            lineWords = l.split()\n",
    "            wordList.extend(lineWords)\n",
    "        \n",
    "    classification = classify_review(wordList, vocabulary)\n",
    "    \n",
    "    if classification == 0:\n",
    "        pos_review_count2 += 1\n",
    "        # This is a positive review\n",
    "    else:\n",
    "        neg_review_count2 += 1\n",
    "        # This is a negative review\n",
    "            \n",
    "print(\"Number positive for NEG test set (incorrect): \", pos_review_count2)\n",
    "print(\"Number negative for NEG test set (correct): \", neg_review_count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
